{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 13: Word2Vec with Game of Thrones\n",
    "This lab explores Word2Vec embeddings using Game of Thrones text data.\n",
    "\n",
    "Objectives:\n",
    "- Understand distributional semantics\n",
    "- Train CBOW and Skip-Gram models\n",
    "- Explore word similarity, analogy, and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72fece4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\AL\n",
      "[nltk_data]     MAKKAH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\AL\n",
      "[nltk_data]     MAKKAH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install gensim nltk plotly --quiet\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import os\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "711dbf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 145020\n",
      "Sample: [['game', 'of', 'thrones', 'book', 'one', 'of', 'song', 'of', 'ice', 'and', 'fire', 'by', 'george', 'martin', 'prologue', 'we', 'should', 'start', 'back', 'gared', 'urged', 'as', 'the', 'woods', 'began', 'to', 'grow', 'dark', 'around', 'them'], ['the', 'wildlings', 'are', 'dead']]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = r\"C:/Users/AL MAKKAH/Desktop/Artificial intelligence lab/Lab13_Assignment\"\n",
    "\n",
    "story = []\n",
    "for filename in os.listdir(DATA_PATH):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(DATA_PATH, filename)\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                corpus = f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            with open(file_path, \"r\", encoding=\"cp1252\") as f:\n",
    "                corpus = f.read()\n",
    "        for sent in sent_tokenize(corpus):\n",
    "            story.append(simple_preprocess(sent))\n",
    "\n",
    "print(\"Number of sentences:\", len(story))\n",
    "print(\"Sample:\", story[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecab0261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6569451, 8628190)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sg=1 → Skip-Gram\n",
    "model_skipgram = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    sg=1\n",
    ")\n",
    "\n",
    "model_skipgram.build_vocab(story)\n",
    "model_skipgram.train(story, total_examples=model_skipgram.corpus_count, epochs=model_skipgram.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb55077c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6568703, 8628190)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sg=0 → CBOW\n",
    "model_cbow = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    sg=0\n",
    ")\n",
    "\n",
    "model_cbow.build_vocab(story)\n",
    "model_cbow.train(story, total_examples=model_cbow.corpus_count, epochs=model_cbow.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73210e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('stormborn', 0.8164581060409546), ('khaleesi', 0.7637990713119507), ('unburnt', 0.7509299516677856), ('targaryen', 0.7417117357254028), ('kneel', 0.7155182957649231), ('dragons', 0.7055129408836365), ('khaleen', 0.6951469779014587), ('dosh', 0.691207230091095), ('dany', 0.6748249530792236), ('undying', 0.6713566184043884)]\n",
      "jon\n",
      "bronn\n",
      "Vector for 'king': [ 0.22312668 -0.19526942  0.2889272   0.27672654  0.0893752   0.16197677\n",
      "  0.35197693  0.47172466 -0.3977285   0.3188624  -0.0992123  -0.39246553\n",
      "  0.30144337  0.13863242 -0.06383487 -0.49485096 -0.24974239  0.06844958\n",
      " -0.307186   -0.09262989 -0.2333644   0.1248661   0.5173552  -0.655453\n",
      " -0.45033014  0.08659264 -0.14802504 -0.22410189 -0.25168437 -0.09285128\n",
      " -0.17524858 -0.01489216  0.2728658  -0.10870969 -0.01117838  0.03562184\n",
      " -0.36498144 -0.1277479  -0.15487489 -0.2818414   0.08132784 -0.35039067\n",
      "  0.23407145  0.04196651  0.09226379 -0.00407417  0.20803142 -0.35804012\n",
      "  0.56385267 -0.22551897 -0.38104966 -0.24528556 -0.25945836  0.05837456\n",
      "  0.54809666  0.14088224  0.02789379 -0.22395426 -0.7156287   0.4351353\n",
      " -0.07134198  0.25050855  0.11228281  0.09567942 -0.80317295  0.28049934\n",
      " -0.48567334 -0.25127256 -0.00579257  0.19078472 -0.55499214  0.20153263\n",
      "  0.22741538 -0.15665421  0.34040615  0.6031866   0.25783065 -0.08938399\n",
      " -0.23189661 -0.23822312 -0.12357322  0.23877281 -0.27389297  0.63866395\n",
      " -0.35325935 -0.45180607  0.0865334  -0.038702    0.4767315   0.24027333\n",
      "  0.28435305  0.18565993 -0.11982976  0.08236589  0.28647947  0.01516832\n",
      "  0.12178419  0.60145783  0.2227805  -0.340246  ]\n",
      "Similarity Arya vs Sansa: 0.7769498\n",
      "Similarity Tywin vs Sansa: 0.40475136\n"
     ]
    }
   ],
   "source": [
    "print(model_skipgram.wv.most_similar('daenerys'))\n",
    "print(model_skipgram.wv.doesnt_match(['jon','rikon','robb','arya','sansa','bran']))\n",
    "print(model_skipgram.wv.doesnt_match(['cersei', 'jaime', 'bronn', 'tyrion']))\n",
    "print(\"Vector for 'king':\", model_skipgram.wv['king'])\n",
    "print(\"Similarity Arya vs Sansa:\", model_skipgram.wv.similarity('arya','sansa'))\n",
    "print(\"Similarity Tywin vs Sansa:\", model_skipgram.wv.similarity('tywin','sansa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b004e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "X = pca.fit_transform(model_skipgram.wv.get_normed_vectors())\n",
    "y = model_skipgram.wv.index_to_key\n",
    "\n",
    "pio.renderers.default = \"browser\"\n",
    "df = pd.DataFrame(X[200:300], columns=[\"x\", \"y\", \"z\"])\n",
    "df[\"label\"] = y[200:300]\n",
    "fig = px.scatter_3d(df, x=\"x\", y=\"y\", z=\"z\", color=\"label\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
